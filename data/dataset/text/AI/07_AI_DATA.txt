Deep learning is the area of artificial intelligence where the real magic is happening right now. Traditionally computers, while being very fast, have not been very smart – they have no ability to learn from their mistakes and have to be given precise instructions in order to carry out any task. Active on Facebook +6621 views in the last 24 hours +10840 views in the last 24 hours Active on LinkedIn +12230 views in the last 24 hours +103050 views in the last 24 hours Deep learning involves building artificial neural networks which attempt to mimic the way organic(living) brains sort and process information. The “deep” in deep learning signifies the use of many layers of neural networks all stacked on top of each other. This data processing configuration is known as a deep neural network, and its complexity means it is able to process data to a more thorough and refined degree than other AI technologies which have come before it. Deep learning is already driving innovation at the cutting edge of artificial intelligence and it can be seen in many applications today. However, as data volumes continue to increase and processing technology becomes more affordable, many more sectors of society are likely to be impacted. Here’s a look at how one of the pioneers - Google - is already using it across many of its products and services. Why is Google interested in deep learning? Google has been a powerful force in championing the use of deep learning – a technology now so prevalent in cutting edge applications that its name is pretty much synonymous with artificial intelligence. There’s a simple reason for this – it works. Putting deep learning to work has enabled data scientists to crack a number of difficult cases which had proved challenging for decades, such as speech and image recognition, and natural language generation. It’s first publicly-discussed explorations of the possibilities of deep learning began with the Google Brain project in 2011. The following year, Google announced that it had built a neural network, designed to simulate human cognitive processes, running on 16,000 computers and which was capable, after studying around 10 million images, of identifying cats. In 2014, Google acquired UK based deep learning startup Deep Mind. Deep Mind pioneered work in connecting existing machine learning techniques to cutting edge research in neuroscience, leading to systems which more accurately resembled “real” intelligence (I.e brains). Deep Mind was responsible for the creation of Alpha Go, which used video games, and later the boardgame Go, to demonstrate the ability of their algorithm to learn how to carry out a task and become increasingly good at it. What does Google use deep learning for across its mail services? While proving the concept in laboratories and games contests, it was also quietly rolled out across many of Google’s services. It’s first practical use was in image recognition, where it was put to work sorting through the millions of images uploaded to the parts of the internet which Google indexes. It does this in order to more accurately classify them, and in turn give users more accurate search results. Google’s latest breakthrough involving deep learning in the field of image analytics is in image enhancement. This involves restoring or filling in detail missing from images, by extrapolating for data that is present, as well as using what it knows about other similar images. Another platform, Google Cloud Video Intelligence focuses on opening up video analytics to new audiences. Video stored on Google’s servers can be segmented and analyzed for content and context, allowing automated summaries to be generated, or even security alerts if the AI thinks something suspicious is going on. Language processing is another area of their services where the tech has been implemented. It’s Google Assistant speech recognition AI uses deep neural networks to learn how to better understand spoken commands and questions. Techniques developed by Google Brain were rolled into this project. More recently, Google’s translation service was also put under the umbrella of Google Brain. The system was rewritten to run on a new platform called Google Neural Machine Translation, moving everything to a deep learning environment. The third primary way Google uses deep learning today on its core services is to provide more useful recommendations on Youtube. Again, Google Brain is behind the technology used here, which monitors and records our viewing habits as we stream content from their servers. Data already showed that suggesting videos that viewers will want to watch next is key to keeping them hooked to the platform, and the ad bucks rolling in. Deep neural networks were put to work studying and learning everything they could about viewers’ habits and preferences, and working out what would keep them glued to their screens.